{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import shutil as sh\n",
    "import os\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\r\n",
      "remote: Enumerating objects: 78, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (78/78), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (61/61), done.\u001b[K\r\n",
      "remote: Total 1472 (delta 40), reused 43 (delta 17), pack-reused 1394\u001b[K\r\n",
      "Receiving objects: 100% (1472/1472), 5.92 MiB | 22.62 MiB/s, done.\r\n",
      "Resolving deltas: 100% (978/978), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv yolov5/* ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/global-wheat-detection/train.csv')\n",
    "bboxs = np.stack(df['bbox'].apply(lambda x: np.fromstring(x[1:-1], sep=',')))\n",
    "for i, column in enumerate(['x', 'y', 'w', 'h']):\n",
    "    df[column] = bboxs[:,i]\n",
    "df.drop(columns=['bbox'], inplace=True)\n",
    "df['x_center'] = df['x'] + df['w']/2\n",
    "df['y_center'] = df['y'] + df['h']/2\n",
    "df['classes'] = 0\n",
    "df = df[['image_id','x', 'y', 'w', 'h','x_center','y_center','classes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>x_center</th>\n",
       "      <th>y_center</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b6ab77fd7</td>\n",
       "      <td>834.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>862.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b6ab77fd7</td>\n",
       "      <td>226.0</td>\n",
       "      <td>548.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_id      x      y      w     h  x_center  y_center  classes\n",
       "0  b6ab77fd7  834.0  222.0   56.0  36.0     862.0     240.0        0\n",
       "1  b6ab77fd7  226.0  548.0  130.0  58.0     291.0     577.0        0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = list(set(df.image_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7896fd56e6e4e68867cf5a6803c4b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3373.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "source = 'train'\n",
    "if True:\n",
    "    for fold in [0]:\n",
    "        val_index = index[len(index)*fold//5:len(index)*(fold+1)//5]\n",
    "        for name,mini in tqdm(df.groupby('image_id')):\n",
    "            if name in val_index:\n",
    "                path2save = 'val2017/'\n",
    "            else:\n",
    "                path2save = 'train2017/'\n",
    "            if not os.path.exists('convertor/fold{}/labels/'.format(fold)+path2save):\n",
    "                os.makedirs('convertor/fold{}/labels/'.format(fold)+path2save)\n",
    "            with open('convertor/fold{}/labels/'.format(fold)+path2save+name+\".txt\", 'w+') as f:\n",
    "                row = mini[['classes','x_center','y_center','w','h']].astype(float).values\n",
    "                row = row/1024\n",
    "                row = row.astype(str)\n",
    "                for j in range(len(row)):\n",
    "                    text = ' '.join(row[j])\n",
    "                    f.write(text)\n",
    "                    f.write(\"\\n\")\n",
    "            if not os.path.exists('convertor/fold{}/images/{}'.format(fold,path2save)):\n",
    "                os.makedirs('convertor/fold{}/images/{}'.format(fold,path2save))\n",
    "            sh.copy(\"../input/global-wheat-detection/{}/{}.jpg\".format(source,name),'convertor/fold{}/images/{}/{}.jpg'.format(fold,path2save,name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\r\n",
      "Namespace(batch_size=2, bucket='', cache_images=False, cfg='../input/panet-config/yolo5_PANET.yaml', data='../input/configyolo5/wheat0.yaml', device='', epochs=40, evolve=False, hyp='', img_size=[1024], multi_scale=False, name='yolov5x_fold4', noautoanchor=False, nosave=False, notest=False, rect=False, resume=False, single_cls=False, weights='../input/selfyolo5/last_yolov5x_fold4.pt')\r\n",
      "Using CUDA device0 _CudaDeviceProperties(name='Tesla P100-PCIE-16GB', total_memory=16280MB)\r\n",
      "\r\n",
      "2020-07-13 12:02:30.934610: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n",
      "Start Tensorboard with \"tensorboard --logdir=runs\", view at http://localhost:6006/\r\n",
      "Hyperparameters {'optimizer': 'SGD', 'lr0': 0.01, 'momentum': 0.937, 'weight_decay': 0.0005, 'giou': 0.05, 'cls': 0.58, 'cls_pw': 1.0, 'obj': 1.0, 'obj_pw': 1.0, 'iou_t': 0.2, 'anchor_t': 4.0, 'fl_gamma': 0.0, 'hsv_h': 0.014, 'hsv_s': 0.68, 'hsv_v': 0.36, 'degrees': 0.0, 'translate': 0.0, 'scale': 0.5, 'shear': 0.0}\r\n",
      "\r\n",
      "                 from  n    params  module                                  arguments                     \r\n",
      "  0                -1  1      8800  models.common.Focus                     [3, 80, 3]                    \r\n",
      "  1                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \r\n",
      "  2                -1  1    315680  models.common.BottleneckCSP             [160, 160, 4]                 \r\n",
      "  3                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \r\n",
      "  4                -1  1   3311680  models.common.BottleneckCSP             [320, 320, 12]                \r\n",
      "  5                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \r\n",
      "  6                -1  1  13228160  models.common.BottleneckCSP             [640, 640, 12]                \r\n",
      "  7                -1  1   7375360  models.common.Conv                      [640, 1280, 3, 2]             \r\n",
      "  8                -1  1   4099840  models.common.SPP                       [1280, 1280, [5, 9, 13]]      \r\n",
      "  9                -1  1  20087040  models.common.BottleneckCSP             [1280, 1280, 4, False]        \r\n",
      " 10                -1  1    820480  models.common.Conv                      [1280, 640, 1, 1]             \r\n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \r\n",
      " 13                -1  1   5435520  models.common.BottleneckCSP             [1280, 640, 4, False]         \r\n",
      " 14                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \r\n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \r\n",
      " 17                -1  1   1360960  models.common.BottleneckCSP             [640, 320, 4, False]          \r\n",
      " 18                -1  1      5778  torch.nn.modules.conv.Conv2d            [320, 18, 1, 1]               \r\n",
      " 19                -2  1    922240  models.common.Conv                      [320, 320, 3, 2]              \r\n",
      " 20          [-1, 14]  1         0  models.common.Concat                    [1]                           \r\n",
      " 21                -1  1   5025920  models.common.BottleneckCSP             [640, 640, 4, False]          \r\n",
      " 22                -1  1     11538  torch.nn.modules.conv.Conv2d            [640, 18, 1, 1]               \r\n",
      " 23                -2  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \r\n",
      " 24          [-1, 10]  1         0  models.common.Concat                    [1]                           \r\n",
      " 25                -1  1  20087040  models.common.BottleneckCSP             [1280, 1280, 4, False]        \r\n",
      " 26                -1  1     23058  torch.nn.modules.conv.Conv2d            [1280, 18, 1, 1]              \r\n",
      " 27      [-1, 22, 18]  1         0  models.yolo.Detect                      [1, [[116, 90, 156, 198, 373, 326], [30, 61, 62, 45, 59, 119], [10, 13, 16, 30, 33, 23]]]\r\n",
      "Model Summary: 407 layers, 8.84337e+07 parameters, 8.84337e+07 gradients\r\n",
      "\r\n",
      "Optimizer groups: 134 .bias, 142 conv.weight, 131 other\r\n",
      "Scanning images: 100%|████████████████████| 2699/2699 [00:00<00:00, 3625.23it/s]\r\n",
      "Scanning labels convertor/fold0/labels/train2017.cache (2699 found, 0 missing, 0\r\n",
      "Scanning images: 100%|██████████████████████| 674/674 [00:00<00:00, 3720.06it/s]\r\n",
      "Scanning labels convertor/fold0/labels/val2017.cache (674 found, 0 missing, 0 em\r\n",
      "\r\n",
      "Analyzing anchors... Best Possible Recall (BPR) = 0.9991\r\n",
      "Image sizes 1024 train, 1024 test\r\n",
      "Using 2 dataloader workers\r\n",
      "Starting training for 40 epochs...\r\n",
      "\r\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\r\n",
      "     35/39     11.2G   0.03397    0.1317         0    0.1657        42      1024\r\n",
      "               Class      Images     Targets           P           R      mAP@.5\r\n",
      "                 all         674    2.97e+04       0.786       0.962       0.963       0.562\r\n",
      "\r\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\r\n",
      "     36/39     11.2G   0.03285    0.1301         0     0.163        64      1024\r\n",
      "               Class      Images     Targets           P           R      mAP@.5\r\n",
      "                 all         674    2.97e+04       0.793       0.963       0.964       0.566\r\n",
      "\r\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\r\n",
      "     37/39     11.2G   0.03264    0.1292         0    0.1619        96      1024\r\n",
      "               Class      Images     Targets           P           R      mAP@.5\r\n",
      "                 all         674    2.97e+04       0.797       0.964       0.966        0.57\r\n",
      "\r\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\r\n",
      "     38/39     11.2G   0.03234    0.1299         0    0.1622        92      1024\r\n",
      "               Class      Images     Targets           P           R      mAP@.5\r\n",
      "                 all         674    2.97e+04       0.794       0.964       0.966       0.571\r\n",
      "\r\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\r\n",
      "     39/39     11.2G    0.0323    0.1281         0    0.1604        34      1024\r\n",
      "               Class      Images     Targets           P           R      mAP@.5\r\n",
      "                 all         674    2.97e+04       0.794       0.964       0.965        0.57\r\n",
      "Optimizer stripped from runs/exp0_yolov5x_fold4/weights/last_yolov5x_fold4.pt, 177.5MB\r\n",
      "Optimizer stripped from runs/exp0_yolov5x_fold4/weights/best_yolov5x_fold4.pt, 177.5MB\r\n",
      "5 epochs completed in 1.089 hours.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python train.py --img 1024 --batch 2 --epochs 40 --data ../input/configyolo5/wheat0.yaml --cfg ../input/panet-config/yolo5_PANET.yaml --name yolov5x_fold4 --weights ../input/selfyolo5/last_yolov5x_fold4.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python train.py --img 1024 --batch 2 --epochs x --data ../input/configyolo5/wheat0.yaml --cfg ../input/panet-config/yolo5_PANET.yaml --name yolov5x_fold4 --weights ../input/panet-config/PANet_0709_v1.pt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0136daac29874200a8603393ce9805a0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7c5caf8ed9d8406885af65ec2ac5f5c5",
       "max": 3373.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3d48b3d651cf42e28bf4190292d64371",
       "value": 3373.0
      }
     },
     "15893140198747d1b06bbbd39fe77c4b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3d48b3d651cf42e28bf4190292d64371": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "65f32b8674e6492bafe2f3ed87a0a9be": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7c5caf8ed9d8406885af65ec2ac5f5c5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c7896fd56e6e4e68867cf5a6803c4b37": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0136daac29874200a8603393ce9805a0",
        "IPY_MODEL_ec164be6a46a4a9b95608bd953d492dd"
       ],
       "layout": "IPY_MODEL_15893140198747d1b06bbbd39fe77c4b"
      }
     },
     "ec164be6a46a4a9b95608bd953d492dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f25946bfe311494f8ee93b950000f7d0",
       "placeholder": "​",
       "style": "IPY_MODEL_65f32b8674e6492bafe2f3ed87a0a9be",
       "value": " 3373/3373 [00:14&lt;00:00, 225.29it/s]"
      }
     },
     "f25946bfe311494f8ee93b950000f7d0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
